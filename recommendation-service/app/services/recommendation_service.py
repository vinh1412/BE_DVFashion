import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
from fastapi import HTTPException
from typing import List, Dict
from app.repositories.product_repository import fetch_products
from app.repositories.interaction_repository import fetch_user_interactions
from app.repositories.config_repository import fetch_recommendation_config

class HybridRecommendationEngine:
    # Kh·ªüi t·∫°o c√°c bi·∫øn c·∫ßn thi·∫øt
    def __init__(self):
        self.products_df = None # DataFrame s·∫£n ph·∫©m
        self.interactions_df = None # DataFrame t∆∞∆°ng t√°c ng∆∞·ªùi d√πng
        self.tfidf_matrix = None # Ma tr·∫≠n TF-IDF cho content-based
        self.vectorizer = None # TF-IDF Vectorizer
        self.user_item_matrix = None # Ma tr·∫≠n user-item cho collaborative filtering
        self.knn_model = None # M√¥ h√¨nh KNN cho collaborative filtering
        
        # C·∫•u h√¨nh m·∫∑c ƒë·ªãnh
        self.content_weight = 0.4
        self.collaborative_weight = 0.6
        self.min_interaction_count = 2
        
        # Tr·ªçng s·ªë cho c√°c lo·∫°i t∆∞∆°ng t√°c
        self.interaction_weights = {
            'VIEW': 1.0,
            'ADD_TO_CART': 2.0,
            'PURCHASE': 5.0,
            'REVIEW': 3.0
        }

    def load_config(self):
        """ƒê·ªçc c·∫•u h√¨nh m√¥ h√¨nh t·ª´ DB"""
        try:
            print("Reloading config from DB...")
            config = fetch_recommendation_config()
            print(f"Loaded config: {config}")
            self.content_weight = float(config.get('content_weight', 0.4))
            self.collaborative_weight = float(config.get('collaborative_weight', 0.6))
            self.min_interaction_count = int(config.get('min_interaction_count', 2))

            print(f"Loaded config: content_weight={self.content_weight}, "
                  f"collab_weight={self.collaborative_weight}, "
                  f"min_interaction={self.min_interaction_count}")
        except Exception as e:
            print("Could not load config from DB, using defaults:", e)

    # T·∫£i d·ªØ li·ªáu s·∫£n ph·∫©m v√† t∆∞∆°ng t√°c
    def load_data(self):
        """Load d·ªØ li·ªáu s·∫£n ph·∫©m v√† t∆∞∆°ng t√°c"""
        
        # Load config tr∆∞·ªõc khi train m√¥ h√¨nh
        self.load_config()
        
        self.products_df = fetch_products()  # ƒê·ªï v√†o self.products_df
        self.interactions_df = fetch_user_interactions() # ƒê·ªï v√†o self.interactions_df
        
        # Content-based features
        self._prepare_content_features() # Build TF-IDF matrix
        
        # Collaborative filtering features
        if not self.interactions_df.empty:
            self._prepare_collaborative_features() # Build CF model

    # Chu·∫©n b·ªã features cho Content-based
    def _prepare_content_features(self):
        """Chu·∫©n b·ªã features cho Content-based"""
        self.products_df['content_features'] = (
            self.products_df['name'].fillna('') + ' ' +
            self.products_df['description'].fillna('') + ' ' +
            self.products_df['material'].fillna('') + ' ' +
            self.products_df['category_name'].fillna('') + ' ' +
            self.products_df['color'].fillna('') + ' ' +
            self.products_df['size_name'].fillna('')
        )
        
        self.vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
        self.tfidf_matrix = self.vectorizer.fit_transform(
            self.products_df['content_features']
        )

    # Chu·∫©n b·ªã features cho Collaborative Filtering
    def _prepare_collaborative_features(self):
        """Chu·∫©n b·ªã User-Item Matrix cho Collaborative Filtering"""
        # T√≠nh ƒëi·ªÉm t∆∞∆°ng t√°c
        self.interactions_df['score'] = self.interactions_df.apply(
            lambda row: (
                self.interaction_weights.get(row['interaction_type'], 1.0) * 
                row['interaction_count'] *
                (row['rating'] / 5.0 if pd.notna(row['rating']) else 1.0)
            ),
            axis=1
        )
        
        # T·∫°o pivot table: users x products
        user_item_df = self.interactions_df.pivot_table(
            index='user_id',
            columns='product_id',
            values='score',
            aggfunc='sum',
            fill_value=0
        )
        
        # Chuy·ªÉn sang sparse matrix
        self.user_item_matrix = csr_matrix(user_item_df.values)
        
        self.user_ids = user_item_df.index.tolist()
        self.product_ids = user_item_df.columns.tolist()
        
        # ƒê·∫øm t·ªïng s·ªë ng∆∞·ªùi d√πng ƒëang c√≥ trong d·ªØ li·ªáu
        n_users = user_item_df.shape[0]
        
        # N·∫øu kh√¥ng ƒë·ªß ng∆∞·ªùi d√πng, b·ªè qua CF
        if n_users < 2:
            # kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ CF
            self.user_item_matrix = None
            self.knn_model = None
            return
        
        n_neighbors = min(20, n_users)
        
        # Train KNN model
        self.knn_model = NearestNeighbors(
            metric='cosine', # D√πng cosine similarity
            algorithm='brute', # D√πng brute-force
            n_neighbors=n_neighbors
        )
        
        # Fit m√¥ h√¨nh v·ªõi ma tr·∫≠n user-item
        self.knn_model.fit(self.user_item_matrix)

    # Chu·∫©n ho√° ƒëi·ªÉm similarity_score
    def normalize_recommendations(self, recs: List[Dict]) -> List[Dict]:
            """Chu·∫©n ho√° similarity_score v·ªÅ [0,1]"""
            if not recs:
                return recs

            scores = [r['similarity_score'] for r in recs]
            min_score, max_score = min(scores), max(scores)

            if max_score == min_score:
                # tr√°nh chia cho 0
                for r in recs:
                    r['similarity_score'] = 1.0
                return recs

            for r in recs:
                r['similarity_score'] = (r['similarity_score'] - min_score) / (max_score - min_score)
            return recs

    # G·ª£i √Ω d·ª±a tr√™n Content-based Filtering
    def get_content_based_recommendations(
        self, 
        product_id: int, 
        num_recommendations: int
    ) -> List[Dict]:
        """G·ª£i √Ω d·ª±a tr√™n n·ªôi dung s·∫£n ph·∫©m"""
        
        # X√°c ƒë·ªãnh index c·ªßa s·∫£n ph·∫©m ƒë·∫ßu v√†o l·∫•y ch·ªâ s·ªë h√†ng
        product_indices = self.products_df[self.products_df['id'] == product_id].index
        
        print("G·ª£i √Ω d·ª±a tr√™n n·ªôi dung s·∫£n ph·∫©m cho product_id:", product_id)
        
        # N·∫øu kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†y trong DataFrame s·∫£n ph·∫©m th√¨ tr·∫£ v·ªÅ l·ªói 404
        if product_indices.empty:
            raise HTTPException(
                status_code=404, 
                detail=f"Product {product_id} not found"
            )
        
        # V·ªã tr√≠ h√†ng c·ªßa s·∫£n ph·∫©m trong ma tr·∫≠n TF-IDF
        product_idx = product_indices[0]
        
        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa s·∫£n ph·∫©m g·ªëc v√† t·∫•t c·∫£ s·∫£n ph·∫©m
        cosine_similarities = cosine_similarity(
            self.tfidf_matrix[product_idx:product_idx+1], 
            self.tfidf_matrix
        ).flatten()
        
        # L·∫•y c√°c ch·ªâ s·ªë c·ªßa s·∫£n ph·∫©m t∆∞∆°ng t·ª±, b·ªè qua ch√≠nh n√≥
        similar_indices = cosine_similarities.argsort()[::-1][1:num_recommendations+1]
        
        recommendations = []
        
        # T·∫°o danh s√°ch g·ª£i √Ω
        for idx in similar_indices:
            product = self.products_df.iloc[idx]
            recommendations.append({
                'product_id': int(product['id']),
                'similarity_score': float(cosine_similarities[idx]),
                'name': product['name'],
                'category': product['category_name'],
                'price': float(product['price']) if product['price'] else None,
                'recommendation_type': 'CONTENT'
            })
        
        # In ra th√¥ng tin g·ª£i √Ω
        return self.normalize_recommendations(recommendations)

    # G·ª£i √Ω d·ª±a tr√™n Collaborative Filtering
    def get_collaborative_recommendations(
        self, 
        user_id: int, 
        num_recommendations: int,
        exclude_items: set = None
    ) -> List[Dict]:
        """G·ª£i √Ω d·ª±a tr√™n h√†nh vi ng∆∞·ªùi d√πng t∆∞∆°ng t·ª±"""
        
        # Ki·ªÉm tra n·∫øu user_item_matrix ch∆∞a ƒë∆∞·ª£c t·∫°o th√¨ tr·∫£ v·ªÅ r·ªóng
        if self.user_item_matrix is None:
            return []
        
        try:
            user_idx = self.user_ids.index(user_id)
        except ValueError:
            # Ng∆∞·ªùi d√πng m·ªõi ch∆∞a c√≥ t∆∞∆°ng t√°c
            return []
        
        if self.knn_model is None or self.user_item_matrix is None:
            return []
        
        # L·∫•y t·ªïng s·ªë ng∆∞·ªùi d√πng ƒë√£ c√≥ trong ma tr·∫≠n
        n_users = self.user_item_matrix.shape[0]
        
        # Ch·ªçn k l√°ng gi·ªÅng
        k = min(11, n_users)
        
        # N·∫øu kh√¥ng ƒë·ªß ng∆∞·ªùi d√πng ƒë·ªÉ t√¨m l√°ng gi·ªÅng th√¨ tr·∫£ v·ªÅ r·ªóng
        if k < 2:
            return [] 
        
        # T√¨m ng∆∞·ªùi d√πng t∆∞∆°ng t·ª±
        distances, indices = self.knn_model.kneighbors(
            self.user_item_matrix[user_idx],
            n_neighbors=k
        )
        
        print("Checking product IDs overlap...")
        print("Products in interactions:", self.interactions_df['product_id'].unique())
        print("Products in products_df:", self.products_df['id'].unique())
        
        # L·∫•y s·∫£n ph·∫©m t·ª´ ng∆∞·ªùi d√πng t∆∞∆°ng t·ª±
        similar_users_indices = indices.flatten()[1:]
        user_products = set(
            self.interactions_df[
                self.interactions_df['user_id'] == user_id
            ]['product_id'].tolist()
        )
        
        product_scores = {}
        for similar_user_idx in similar_users_indices:
            similar_user_id = self.user_ids[similar_user_idx]
            similar_user_products = self.interactions_df[
                self.interactions_df['user_id'] == similar_user_id
            ]
            
            for _, row in similar_user_products.iterrows():
                prod_id = row['product_id']
                # if prod_id not in user_products:
                # if not allow_seen_items and prod_id in user_products:
                #     continue
                if exclude_items and prod_id in exclude_items:
                    continue
                score = row['score']
                product_scores[prod_id] = product_scores.get(prod_id, 0) + score
        
        # S·∫Øp x·∫øp v√† l·∫•y top N
        top_products = sorted(
            product_scores.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:num_recommendations]
        
        recommendations = []
        for prod_id, score in top_products:
            product = self.products_df[self.products_df['id'] == prod_id]
            if not product.empty:
                product = product.iloc[0]
                recommendations.append({
                    'product_id': int(prod_id),
                    'similarity_score': float(score),
                    'name': product['name'],
                    'category': product['category_name'],
                    'price': float(product['price']) if product['price'] else None,
                    'recommendation_type': 'COLLABORATIVE'
                })

        print(f"User {user_id} ‚Üí {len(recommendations)} CF recommendations: {[r['product_id'] for r in recommendations]}")
        return self.normalize_recommendations(recommendations)
    
    # G·ª£i √Ω d·ª±a tr√™n Hybrid (K·∫øt h·ª£p Content-based v√† Collaborative Filtering)
    def get_hybrid_recommendations(
        self,
        user_id: int = None,
        product_id: int = None,
        num_recommendations: int = 10,
        exclude_items: set = None
    ) -> List[Dict]:
        """K·∫øt h·ª£p Content-based v√† Collaborative Filtering"""
        
        # ƒê·∫£m b·∫£o c·∫•u h√¨nh m·ªõi nh·∫•t ƒë∆∞·ª£c t·∫£i
        self.load_config()
        
        content_recs = []
        collab_recs = []
        
        print(f"Hybrid weights: content={self.content_weight}, collab={self.collaborative_weight}, min_interaction={self.min_interaction_count}")
        
        print("L·∫•y g·ª£i √Ω hybrid cho user_id:", user_id, "v√† product_id:", product_id)
        
        # L·∫•y g·ª£i √Ω t·ª´ content-based
        if product_id:
            content_recs = self.get_content_based_recommendations(
                product_id, 
                num_recommendations * 2
            )
            print(f"\nTop {len(content_recs)} Content-Based Recs for product {product_id}:")
            for rec in content_recs[:5]:
                print(f"   - {rec['product_id']} | {rec['name']} | score={rec['similarity_score']:.4f}")
        
        # L·∫•y g·ª£i √Ω t·ª´ collaborative filtering
        if user_id:
            user_interactions = self.interactions_df[self.interactions_df['user_id'] == user_id]
            interaction_count = len(user_interactions)

            # Ch·ªâ d√πng CF n·∫øu ng∆∞·ªùi d√πng c√≥ ƒë·ªß t∆∞∆°ng t√°c
            if interaction_count >= self.min_interaction_count:
                print(f"User {user_id} c√≥ {interaction_count} t∆∞∆°ng t√°c ‚Üí d√πng Collaborative Filtering")
                collab_recs = self.get_collaborative_recommendations(
                    user_id,
                    num_recommendations * 2,
                    exclude_items=exclude_items
                )
                print(f"\nTop {len(collab_recs)} Collaborative Recs for user {user_id}:")
                for rec in collab_recs[:5]:
                    print(f"   - {rec['product_id']} | {rec['name']} | score={rec['similarity_score']:.4f}")
            else:
                print(f"User {user_id} ch·ªâ c√≥ {interaction_count} t∆∞∆°ng t√°c (< {self.min_interaction_count}) ‚Üí b·ªè qua CF")
                collab_recs = []
                
        # Chu·∫©n ho√° c·∫£ hai ngu·ªìn ƒëi·ªÉm tr∆∞·ªõc khi tr·ªôn
        content_recs = self.normalize_recommendations(content_recs)
        collab_recs = self.normalize_recommendations(collab_recs)
        
        # K·∫øt h·ª£p k·∫øt qu·∫£ (60% collaborative, 40% content)
        all_recommendations = {}
        
        for rec in collab_recs:
            pid = rec['product_id']
            all_recommendations[pid] = {
                **rec,
                'similarity_score': rec['similarity_score'] * self.collaborative_weight,
                'recommendation_type': 'COLLABORATIVE'
            }
        
        for rec in content_recs:
            pid = rec['product_id']
            if pid in all_recommendations:
                all_recommendations[pid]['similarity_score'] += rec['similarity_score'] * self.content_weight
                all_recommendations[pid]['recommendation_type'] = 'HYBRID'
            else:
                all_recommendations[pid] = {
                    **rec,
                    'similarity_score': rec['similarity_score'] * self.content_weight
                }
        
        # S·∫Øp x·∫øp v√† tr·∫£ v·ªÅ top N
        final_recommendations = sorted(
            all_recommendations.values(),
            key=lambda x: x['similarity_score'],
            reverse=True
        )[:num_recommendations]
        print("\nTop Hybrid Results (combined & sorted):")
        for rec in final_recommendations:
            print(f"   - {rec['product_id']} | {rec['name']} | {rec['recommendation_type']} | final_score={rec['similarity_score']:.4f}")

        print("=" * 80 + "\n")
        return final_recommendations
    
    def get_recommendations_by_text(
    self,
    query: str,
    num_recommendations: int = 10
    ) -> List[Dict]:
        
        """G·ª£i √Ω s·∫£n ph·∫©m d·ª±a tr√™n truy v·∫•n text (d√†nh cho chatbot)."""
        if self.vectorizer is None or self.tfidf_matrix is None:
            print("‚ö†Ô∏è TF-IDF matrix ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.")
            return []

        print(f"üîç Searching for: '{query}'")

        try:
            # Vector h√≥a truy v·∫•n b·∫±ng TF-IDF
            query_vector = self.vectorizer.transform([query])

            # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine v·ªõi t·∫•t c·∫£ s·∫£n ph·∫©m
            similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()

            # L·∫•y top ch·ªâ s·ªë c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t (b·ªè tr∆∞·ªõc ph·∫ßn ‚â§ 0)
            positive_indices = np.where(similarities > 0)[0]
            if len(positive_indices) == 0:
                print("‚ö†Ô∏è No product found with similarity > 0.")
                return []

            # L·∫•y top N trong c√°c s·∫£n ph·∫©m c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng d∆∞∆°ng
            top_indices = similarities[positive_indices].argsort()[::-1][:num_recommendations]
            top_indices = positive_indices[top_indices]

            recommendations = []
            for idx in top_indices:
                sim_score = float(similarities[idx])
                if sim_score <= 1e-6:
                    continue  # b·ªè c√°c k·∫øt qu·∫£ kh√¥ng kh·ªõp

                product = self.products_df.iloc[idx]

                # L·∫•y th√¥ng tin chi ti·∫øt (c√≥ ki·ªÉm tra null)
                product_id = int(product.get("id"))
                name = str(product.get("name", "")).strip()
                category = str(product.get("category_name", "")).strip()
                color = str(product.get("color", "")).strip()
                size = str(product.get("size_name", "")).strip()
                material = str(product.get("material", "")).strip()

                # L·∫•y gi√°: n·∫øu c√≥ sale_price th√¨ d√πng, n·∫øu kh√¥ng th√¨ price
                base_price = product.get("sale_price") or product.get("price")
                price = float(base_price) if pd.notna(base_price) else None

                recommendations.append({
                    "product_id": product_id,
                    "name": name,
                    "category": category,
                    "color": color,
                    "size": size,
                    "material": material,
                    "price": price,
                    "similarity_score": sim_score,
                    "recommendation_type": "TEXT_SEARCH"
                })

            # Lo·∫°i b·ªè tr√πng l·∫∑p (c√πng s·∫£n ph·∫©m nhi·ªÅu size)
            unique_recs = {r["product_id"]: r for r in recommendations}.values()

            # Chu·∫©n ho√° ƒëi·ªÉm similarity v·ªÅ [0,1]
            normalized = self.normalize_recommendations(list(unique_recs))
            
            normalized = [r for r in normalized if r["similarity_score"] > 0]

            print(f"‚úÖ Found {len(normalized)} products for query: '{query}'")
            return normalized

        except Exception as e:
            print(f"‚ùå Error in text search: {e}")
            return []

recommendation_engine = HybridRecommendationEngine()
